# ğŸ§  Machine Learning Pipeline with DVC, MLflow & DagsHub

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10-blue?logo=python" />
  <img src="https://img.shields.io/badge/DVC-Enabled-purple?logo=dvc" />
  <img src="https://img.shields.io/badge/MLflow-Tracking-orange?logo=mlflow" />
  <img src="https://img.shields.io/badge/DagsHub-Connected-yellow" />
  <img src="https://img.shields.io/badge/Scikit--Learn-RandomForest-green?logo=scikit-learn" />
</p>

<p align="center">
  <img height="140" src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/python.svg" />
  <img height="140" src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/dvc.svg" />
  <img height="140" src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/mlflow.svg" />
  <img height="140" src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/github.svg" />
</p>

---

## ğŸ“ Project Summary

This project delivers a fully modular and reproducible  
**âš™ï¸ Machine Learning Pipeline** powered by **DVC**, **MLflow**, and **DagsHub**,  
designed to train a **ğŸŒ² Random Forest Classifier** on the  
**ğŸ©º Pima Indians Diabetes Dataset**.

The pipeline consists of **three core stages**, each visually represented below:

ğŸ“¥ RAW DATA
â”‚
â–¼
ğŸ§¹ PREPROCESSING â”€â”€â–º ğŸ“„ CLEAN DATA
â”‚
â–¼
ğŸ¤– TRAINING â”€â”€â–º ğŸ¯ TRAINED MODEL
â”‚
â–¼
ğŸ“Š EVALUATION â”€â”€â–º ğŸ“ˆ METRICS + REPORTS (MLflow)

---

### ğŸ”¹ **ğŸ§¹ Preprocessing**  
`preprocess.py`  
- Loads raw dataset  
- Applies cleaning & formatting  
- Saves consistent output to `data/processed/`  
- Ensures every run uses identical processed data  

âœ” Powered by: **DVC Data Versioning**  
âœ” Output: `data/processed/data.csv`  

---

### ğŸ”¹ **ğŸ¤– Training**  
`train.py`  
- Trains Random Forest model with Grid Search  
- Logs everything to MLflow:  
  - ğŸ“ˆ Accuracy  
  - âš™ï¸ Hyperparameters (`n_estimators`, `max_depth`, etc.)  
  - ğŸ“Š Confusion Matrix  
  - ğŸ§¾ Classification Report  
  - ğŸ“¦ Trained Model Artifact  

âœ” Model versioned with **DVC**  
âœ” Metrics + Params tracked via **MLflow**  

---

### ğŸ”¹ **ğŸ“Š Evaluation**  
`evaluate.py`  
- Loads trained model  
- Evaluates accuracy on test data  
- Logs final performance metrics & reports to MLflow  

âœ” Enables easy experiment comparison  
âœ” Fully reproducible evaluation  

---

## ğŸ¯ Why This Pipeline?

### âœ” **Reproducibility**  
ğŸ“¦ **DVC** ensures any change in data/code/parameters reruns only the necessary stages â€” guaranteeing identical results across environments.

### âœ” **Experimentation**  
ğŸ“˜ **MLflow** makes it effortless to compare:  
- Runs  
- Hyperparameters  
- Metrics  
- Models  

### âœ” **Collaboration**  
â˜ï¸ **DagsHub** + Git + DVC + MLflow =  
A complete cloud-hosted collaborative MLOps workspace.

### âœ” **Research & Team Use**  
Ideal for:  
- ML research workflows  
- Data science teams  
- Reproducible MLOps education  
- Model lifecycle management  

---

## ğŸ›  Tech Stack

| Icon | Tool | Purpose |
|------|------|---------|
| ğŸ | Python | Core ML logic |
| ğŸ“¦ | DVC | Dataset & model versioning |
| ğŸ“˜ | MLflow | Experiment tracking |
| â˜ï¸ | DagsHub | Remote DVC + MLflow hosting |
| ğŸŒ² | RandomForest | Machine learning model |
| ğŸ”¢ | Scikit-learn | ML algorithms & evaluation |

---

## ğŸ§© DVC Pipeline Stage Creation (Reference)

```bash
# Preprocessing Stage
dvc stage add -n preprocess \
    -p preprocess.input,preprocess.output \
    -d src/preprocess.py -d data/raw/data.csv \
    -o data/processed/data.csv \
    python src/preprocess.py

# Training Stage
dvc stage add -n train \
    -p train.data,train.model,train.random_state,train.n_estimators,train.max_depth \
    -d src/train.py -d data/raw/data.csv \
    -o models/model.pkl \
    python src/train.py

# Evaluation Stage
dvc stage add -n evaluate \
    -d src/evaluate.py -d models/model.pkl -d data/raw/data.csv \
    python src/evaluate.py
