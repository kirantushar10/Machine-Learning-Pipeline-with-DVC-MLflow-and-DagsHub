# ğŸ§  Machine Learning Pipeline with DVC, MLflow & DagsHub

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10-blue?logo=python" />
  <img src="https://img.shields.io/badge/DVC-Enabled-purple?logo=dvc" />
  <img src="https://img.shields.io/badge/MLflow-Tracking-orange?logo=mlflow" />
  <img src="https://img.shields.io/badge/DagsHub-Connected-yellow" />
  <img src="https://img.shields.io/badge/Scikit--Learn-RandomForest-green?logo=scikit-learn" />
</p>

<p align="center">
  <img height="140" src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/python.svg" />
  <img height="140" src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/dvc.svg" />
  <img height="140" src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/mlflow.svg" />
  <img height="140" src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/github.svg" />
</p>

---

## ğŸ“ Project Summary

This project demonstrates how to build a complete **end-to-end Machine Learning pipeline** using:

- **DVC** â†’ Dataset & model versioning  
- **MLflow** â†’ Experiment tracking  
- **DagsHub** â†’ Remote storage + hosted MLflow  
- **Scikit-learn** â†’ RandomForest Classifier  
- **Git** â†’ Code version control  

The pipeline trains a **Random Forest Classifier** on the **Pima Indians Diabetes Dataset** with clear modular stages:

---

# ğŸ“ Project Summary

This project demonstrates how to build an end-to-end Machine Learning workflow using **DVC** for versioning and **MLflow** for experiment tracking.  
A **Random Forest Classifier** is trained on the **Pima Indians Diabetes Dataset**, with the pipeline organized into clear stages:

### ğŸ”§ Preprocessing  
Runs `preprocess.py` â†’ loads raw CSV â†’ outputs a clean processed dataset.  
Ensures consistent data for every ML run.

### ğŸ¤– Training  
`train.py` handles:
- Grid Search hyperparameter tuning  
- Random Forest model training  
- MLflow logging for metrics & artifacts  
- DVC model versioning  

### ğŸ“Š Evaluation  
`evaluate.py`:
- Loads the trained model  
- Computes accuracy  
- Logs evaluation metrics & reports to MLflow  

### ğŸ¯ Why this setup?
- âœ” Reproducible experiments  
- âœ” Structured pipeline with automated stage execution  
- âœ” Easy experiment comparison  
- âœ” Perfect for research, teaching, or team collaboration  

---

# ğŸ“ Project Structure

